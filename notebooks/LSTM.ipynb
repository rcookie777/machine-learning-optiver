{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HT27bB1StMsQ",
        "outputId": "5b335937-f6d0-400a-b347-c1b06cce9cb4"
      },
      "outputs": [],
      "source": [
        "#!pip3 install scikeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r7iXs-3lyE3V"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-06 18:13:06.724700: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Bidirectional\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, f1_score, mean_absolute_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from scikeras.wrappers import KerasClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR7Dcyz-FEbs"
      },
      "source": [
        "##Data Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yOnBG6OE_2HU"
      },
      "outputs": [],
      "source": [
        "# Functions I found and adjusted to help with data prep\n",
        "# https://medium.com/@john.kosinski/preparing-and-shaping-timeseries-data-for-keras-lstm-input-part-two-ad17f6ab450\n",
        "\n",
        "# extract X with the given number of timesteps\n",
        "# df: the DataFrame\n",
        "# ntimesteps: number of timesteps\n",
        "#\n",
        "def extract_X(df: pd.DataFrame, ntimesteps: int):\n",
        "    features = len(df.columns)\n",
        "    X = list()\n",
        "\n",
        "    #offset for timesteps\n",
        "    offsets = list()\n",
        "    for i in range (ntimesteps, 0, -1):\n",
        "        offsets.append(df.shift(i))\n",
        "\n",
        "    #combine timestep columns into rows\n",
        "    combined = pd.concat(offsets, axis=1)\n",
        "    combined = combined.tail(-ntimesteps)\n",
        "    combined.drop(combined.tail(1).index, inplace=True)\n",
        "\n",
        "    #reshape each row (timesteps, features)\n",
        "    for i in range(len(combined)):\n",
        "        row = combined.iloc[i].to_numpy()\n",
        "        xrow = list()\n",
        "        for n in range(ntimesteps):\n",
        "            xrow.append(row[n*features:(n*features)+features])\n",
        "        X.append(xrow)\n",
        "\n",
        "    #return as numpy array\n",
        "    return np.array(X)\n",
        "\n",
        "# extract y column (the col to be predicted)\n",
        "# df: the DataFrame\n",
        "# col_name: the name of the column to be predicted\n",
        "# ntimesteps: number of timesteps\n",
        "#\n",
        "def extract_y(df: pd.DataFrame, col_name: str, ntimesteps: int):\n",
        "    shifted = df.shift(-1)\n",
        "    shifted = shifted.head(-2)\n",
        "    shifted = shifted.tail(-(ntimesteps-1))\n",
        "    return shifted[col_name].values\n",
        "\n",
        "class DataSet:\n",
        "    def __init__(self, X, y):\n",
        "        if X.ndim != 3:\n",
        "            raise Exception(\"Expected a 3-dimensional array for X\")\n",
        "        if y.ndim != 1:\n",
        "            raise Exception(\"Expected a 1-dimensional array for y\")\n",
        "        if len(X) != len(y):\n",
        "            raise Exception(\"Length of X and y must be the same\")\n",
        "\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def train_test_split(self, test_size=0.2):\n",
        "        # Calculate the number of samples for testing\n",
        "        num_samples = len(self.X)\n",
        "        num_test_samples = int(num_samples * test_size)\n",
        "\n",
        "        # Shuffle indices\n",
        "        indices = np.random.permutation(num_samples)\n",
        "\n",
        "        # Split indices into training and testing\n",
        "        test_indices = indices[:num_test_samples]\n",
        "        train_indices = indices[num_test_samples:]\n",
        "\n",
        "        # Split X and y based on indices\n",
        "        X_train, y_train = self.X[train_indices], self.y[train_indices]\n",
        "        X_test, y_test = self.X[test_indices], self.y[test_indices]\n",
        "\n",
        "        # Create DataSet objects for training and testing sets\n",
        "        train_data_set = DataSet(X_train, y_train)\n",
        "        test_data_set = DataSet(X_test, y_test)\n",
        "\n",
        "        return train_data_set, test_data_set\n",
        "\n",
        "    @property\n",
        "    def size(self):\n",
        "        return len(self.X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YlhOn-2T08PF"
      },
      "outputs": [],
      "source": [
        "# load the dataset\n",
        "df = pd.read_csv(\"/mnt/scratch/tairaeli/cse_dat/train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "qQ9_7THOA_X9",
        "outputId": "afaa0150-8551-4e6c-c578-72880199353c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date_id</th>\n",
              "      <th>target_change</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>573</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5236980</th>\n",
              "      <td>480</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5237180</th>\n",
              "      <td>480</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5237380</th>\n",
              "      <td>480</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5237580</th>\n",
              "      <td>480</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5237780</th>\n",
              "      <td>480</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26455 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         date_id  target_change\n",
              "0              0           -1.0\n",
              "191            0            1.0\n",
              "382            0            1.0\n",
              "573            0            1.0\n",
              "764            0            1.0\n",
              "...          ...            ...\n",
              "5236980      480            1.0\n",
              "5237180      480            1.0\n",
              "5237380      480           -1.0\n",
              "5237580      480            1.0\n",
              "5237780      480            1.0\n",
              "\n",
              "[26455 rows x 2 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# drop na values\n",
        "df.dropna()\n",
        "\n",
        "# calulate ratio\n",
        "df['bid_ask_ratio'] = df['bid_size']/df['ask_size']\n",
        "\n",
        "# create target variable\n",
        "df[\"target_change\"] = np.ones_like(df[\"target\"])\n",
        "df.loc[df[\"target\"]<0,'target_change'] = -1\n",
        "\n",
        "# Select features and target\n",
        "selected_features = ['ask_size', 'imbalance_size', 'matched_size', 'bid_size', 'bid_ask_ratio', 'reference_price']\n",
        "\n",
        "# use only stock_id 0\n",
        "df = df[df['stock_id'] == 0]\n",
        "df_selected = df[selected_features]\n",
        "target = df[['date_id', 'target_change']]\n",
        "\n",
        "df_selected\n",
        "target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaUe0yhOPbrx",
        "outputId": "d937d44f-971d-4a62-decf-0150970142ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(26439, 15, 6)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(df_selected)\n",
        "# Convert scaled data back to a DataFrame\n",
        "scaled_df = pd.DataFrame(data=scaled_data, columns=df_selected.columns)\n",
        "\n",
        "\n",
        "timesteps = 15\n",
        "# Format data for LSTM input (sample/batches, timesteps, features)\n",
        "dataset = DataSet(extract_X(df_selected, timesteps), extract_y(target, 'target_change', timesteps))\n",
        "dataset.X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8VHG3zRl41m",
        "outputId": "298c9044-187d-4955-ddcd-b2118cc25e69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(23796, 15, 6)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.random.seed = 156\n",
        "# Split into train and test\n",
        "tr_data, te_data = dataset.train_test_split(test_size = .1)\n",
        "tr_data.X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaLpmut-yE3a"
      },
      "source": [
        "## LSTM Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BZGFvbq-rjv3"
      },
      "outputs": [],
      "source": [
        "# Function to create LSTM model\n",
        "def create_lstm_model(neurons=64, activation='relu',\n",
        "                          optimizer='Adam', loss = 'binary_crossentropy',\n",
        "                              learning_rate = 0.001):\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(neurons, activation='relu'), input_shape=(timesteps, tr_data.X.shape[2])))\n",
        "    model.add(Dense(1, activation=activation))\n",
        "\n",
        "    # Set optimizer based on input string\n",
        "    if optimizer == 'Adam':\n",
        "        opt = Adam(learning_rate = learning_rate)\n",
        "    elif optimizer == 'SGD':\n",
        "        opt = SGD(learning_rate = learning_rate)\n",
        "    elif optimizer == 'RMSprop':\n",
        "        opt = RMSprop(learning_rate = learning_rate)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown optimizer: \" + optimizer)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8sxXeBuBJX2",
        "outputId": "4afea022-d441-42b8-9a7d-7852b3bbce7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-06 18:13:52.091432: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-06 18:13:52.096147: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-06 18:13:52.096146: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-06 18:13:52.096436: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-06 18:13:52.096688: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-06 18:13:52.096688: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/mnt/scratch/tairaeli/anaconda3/envs/tf/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/mnt/scratch/tairaeli/anaconda3/envs/tf/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/mnt/scratch/tairaeli/anaconda3/envs/tf/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/mnt/scratch/tairaeli/anaconda3/envs/tf/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "2024-04-06 18:13:54.753461: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 7. Tune using inter_op_parallelism_threads for best performance.\n",
            "2024-04-06 18:13:54.753478: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 7. Tune using inter_op_parallelism_threads for best performance.\n",
            "2024-04-06 18:13:54.753476: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 7. Tune using inter_op_parallelism_threads for best performance.\n",
            "2024-04-06 18:13:54.753480: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 7. Tune using inter_op_parallelism_threads for best performance.\n",
            "/mnt/scratch/tairaeli/anaconda3/envs/tf/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/mnt/scratch/tairaeli/anaconda3/envs/tf/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "2024-04-06 18:13:54.818710: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 7. Tune using inter_op_parallelism_threads for best performance.\n",
            "2024-04-06 18:13:54.820819: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 7. Tune using inter_op_parallelism_threads for best performance.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Perform grid search\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# change n_jobs to -1 to parallelize or None to go one by one\u001b[39;00m\n\u001b[1;32m     17\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtr_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/scratch/tairaeli/anaconda3/envs/tf/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/scratch/tairaeli/anaconda3/envs/tf/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m/mnt/scratch/tairaeli/anaconda3/envs/tf/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/scratch/tairaeli/anaconda3/envs/tf/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
            "File \u001b[0;32m/mnt/scratch/tairaeli/anaconda3/envs/tf/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/scratch/tairaeli/anaconda3/envs/tf/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
            "File \u001b[0;32m/mnt/scratch/tairaeli/anaconda3/envs/tf/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
            "File \u001b[0;32m/mnt/scratch/tairaeli/anaconda3/envs/tf/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "File \u001b[0;32m/mnt/scratch/tairaeli/anaconda3/envs/tf/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
            "File \u001b[0;32m/mnt/scratch/tairaeli/anaconda3/envs/tf/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Define parameters for grid search\n",
        "param_grid = {\n",
        "    'neurons': [32, 64, 128],\n",
        "    'activation': ['relu', 'tanh', 'sigmoid', 'linear','swish'],\n",
        "    'optimizer': ['Adam', 'SGD', 'RMSprop'],\n",
        "    'learning_rate': [0.1, 0.01, 0.001, 0.0001]\n",
        "}\n",
        "\n",
        "# Create KerasClassifier wrapper\n",
        "model = KerasClassifier(build_fn=create_lstm_model, epochs=20, verbose=0,\n",
        "                        activation=['relu', 'tanh', 'sigmoid', 'linear','swish'],\n",
        "                        neurons = [32, 64, 128],\n",
        "                        learning_rate = [0.1, 0.01, 0.001, 0.0001])\n",
        "\n",
        "# Perform grid search\n",
        "# change n_jobs to -1 to parallelize or None to go one by one\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs = 6)\n",
        "grid_result = grid.fit(tr_data.X, tr_data.y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdpgQovRFjGH"
      },
      "source": [
        "##Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ucS4uscLtabm"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'grid_result' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Summarize results\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m using \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[43mgrid_result\u001b[49m\u001b[38;5;241m.\u001b[39mbest_score_, grid_result\u001b[38;5;241m.\u001b[39mbest_params_))\n\u001b[1;32m      3\u001b[0m means \u001b[38;5;241m=\u001b[39m grid_result\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m stds \u001b[38;5;241m=\u001b[39m grid_result\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_test_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "\u001b[0;31mNameError\u001b[0m: name 'grid_result' is not defined"
          ]
        }
      ],
      "source": [
        "# Summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "id": "MmtSyK3MHl-C",
        "outputId": "c6e64a48-eb44-4d0a-ff80-612de4893dde"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-06 18:15:49.776779: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "152/744 [=====>........................] - ETA: 4:50 - loss: 6.2086 - accuracy: 0.2136"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# neurons = params['neurons']\n",
        "# activation = params['activation']\n",
        "# lr = params['learning_rate']\n",
        "# opt = params['optimizer']\n",
        "\n",
        "# {'activation': 'swish', 'learning_rate': 0.0001, 'neurons': 128, 'optimizer': 'SGD'}\n",
        "\n",
        "model = create_lstm_model(neurons=128, activation='swish', learning_rate=0.0001, optimizer='SGD')\n",
        "\n",
        "# model = create_lstm_model(neurons=128, activation='tanh', learning_rate=0.001, optimizer='Adam')\n",
        "model.fit(tr_data.X, tr_data.y, epochs=20, verbose=1)\n",
        "\n",
        "loss, accuracy = model.evaluate(te_data.X, te_data.y)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "y_pred = model.predict(te_data.X)\n",
        "cm = confusion_matrix(te_data.y, y_pred , normalize='pred')\n",
        "df_cm = pd.DataFrame(cm)\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = confusion_matrix(te_data.y, y_pred , normalize='pred')\n",
        "df_cm = pd.DataFrame(cm)\n",
        "plt.figure(figsize = (10,7))\n",
        "ax = sn.heatmap(df_cm, annot=True)\n",
        "ax.set_xlabel(\"True Values\",fontsize=17)\n",
        "ax.set_ylabel(\"Predicted Values\",fontsize=17)\n",
        "ax.set_xticklabels([\"Positive\",\"Negative\"], fontsize=15)\n",
        "ax.set_yticklabels([\"Positive\",\"Negative\"],fontsize=15)\n",
        "ax.set_title(\"XGBoost Confusion Matrix\", fontsize=20)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouMi090tciQm",
        "outputId": "c5ce52a4-9819-4d5b-9949-8e986f6dc9d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-Score: 0.6422868915786762\n",
            "MAE: 1.0510783200908058\n"
          ]
        }
      ],
      "source": [
        "f1_score = f1_score(y_pred, te_data.y)\n",
        "print(f'F1-Score: {f1_score}')\n",
        "\n",
        "mae = mean_absolute_error(y_pred, te_data.y)\n",
        "print(f'MAE: {mae}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
